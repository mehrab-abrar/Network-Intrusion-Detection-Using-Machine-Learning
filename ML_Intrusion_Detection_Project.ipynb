{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2efa7a3",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection based on Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa14e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15011a7",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e95f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"networkintrusion.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce2301",
   "metadata": {},
   "source": [
    "$head()$ will display the top 5 observations of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83362fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ        0.0        0.0     0   \n",
       "1         0           tcp   private   REJ        0.0        0.0     0   \n",
       "2         2           tcp  ftp_data    SF    12983.0        0.0     0   \n",
       "3         0          icmp     eco_i    SF       20.0        0.0     0   \n",
       "4         1           tcp    telnet  RSTO        0.0       15.0     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  10   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  86   \n",
       "3               0       0    0  ...                  57   \n",
       "4               0       0    0  ...                  86   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.04                    0.06   \n",
       "1                    0.00                    0.06   \n",
       "2                    0.61                    0.04   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.31                    0.17   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.61                         0.02   \n",
       "3                         1.00                         0.28   \n",
       "4                         0.03                         0.02   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                  1.00   \n",
       "1                   0.0                       0.0                  1.00   \n",
       "2                   0.0                       0.0                  0.00   \n",
       "3                   0.0                       0.0                  0.00   \n",
       "4                   0.0                       0.0                  0.83   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      1.00  anomaly  \n",
       "1                      1.00  anomaly  \n",
       "2                      0.00   normal  \n",
       "3                      0.00  anomaly  \n",
       "4                      0.71  anomaly  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4c8c4",
   "metadata": {},
   "source": [
    "### Analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11664e",
   "metadata": {},
   "source": [
    "$info()$ helps to understand the data type and information about data, including the number of records in each column, data having null or not null, Data type, the memory usage of the dataset.\n",
    "\n",
    "We can find that the network intrusion dataset has 40 columns, among them, \"protocol_type\", \"service\", \"flag\", and \"class\" columns are object type or categorical features (Not numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21be6d2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22544 entries, 0 to 22543\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     22544 non-null  int64  \n",
      " 1   protocol_type                22544 non-null  object \n",
      " 2   service                      22544 non-null  object \n",
      " 3   flag                         22544 non-null  object \n",
      " 4   src_bytes                    22538 non-null  float64\n",
      " 5   dst_bytes                    22538 non-null  float64\n",
      " 6   land                         22544 non-null  int64  \n",
      " 7   wrong_fragment               22544 non-null  int64  \n",
      " 8   urgent                       22544 non-null  int64  \n",
      " 9   hot                          22544 non-null  int64  \n",
      " 10  num_failed_logins            22544 non-null  int64  \n",
      " 11  logged_in                    22544 non-null  int64  \n",
      " 12  num_compromised              22544 non-null  int64  \n",
      " 13  root_shell                   22544 non-null  int64  \n",
      " 14  num_root                     22544 non-null  int64  \n",
      " 15  num_shells                   22544 non-null  int64  \n",
      " 16  num_access_files             22544 non-null  int64  \n",
      " 17  num_outbound_cmds            22544 non-null  int64  \n",
      " 18  is_host_login                22544 non-null  int64  \n",
      " 19  is_guest_login               22544 non-null  int64  \n",
      " 20  count                        22535 non-null  float64\n",
      " 21  srv_count                    22535 non-null  float64\n",
      " 22  serror_rate                  22544 non-null  float64\n",
      " 23  srv_serror_rate              22544 non-null  float64\n",
      " 24  rerror_rate                  22544 non-null  float64\n",
      " 25  srv_rerror_rate              22544 non-null  float64\n",
      " 26  same_srv_rate                22544 non-null  float64\n",
      " 27  diff_srv_rate                22544 non-null  float64\n",
      " 28  srv_diff_host_rate           22544 non-null  float64\n",
      " 29  dst_host_count               22544 non-null  int64  \n",
      " 30  dst_host_srv_count           22544 non-null  int64  \n",
      " 31  dst_host_same_srv_rate       22544 non-null  float64\n",
      " 32  dst_host_diff_srv_rate       22544 non-null  float64\n",
      " 33  dst_host_same_src_port_rate  22544 non-null  float64\n",
      " 34  dst_host_srv_diff_host_rate  22544 non-null  float64\n",
      " 35  dst_host_serror_rate         22544 non-null  float64\n",
      " 36  dst_host_srv_serror_rate     22544 non-null  float64\n",
      " 37  dst_host_rerror_rate         22544 non-null  float64\n",
      " 38  dst_host_srv_rerror_rate     22544 non-null  float64\n",
      " 39  class                        22544 non-null  object \n",
      "dtypes: float64(19), int64(17), object(4)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e8ce6",
   "metadata": {},
   "source": [
    "Some machine learning algorithms can handle categorical features directly without requiring them to be converted to numerical values. For example, Decision Trees and Random Forests can handle categorical variables naturally by splitting on different categories.\n",
    "\n",
    "However, many other algorithms, such as logistic regression, support vector machines, and neural networks, require numerical input. In such cases, converting categorical features to numerical values becomes necessary. This process is called \"encoding\" categorical variables.\n",
    "\n",
    "Since we will work with all classification models, we will use LabelEncoder() to convert the categorical features to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3455f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['protocol_type'] = label_encoder.fit_transform(data['protocol_type'])\n",
    "data['service'] = label_encoder.fit_transform(data['service'])\n",
    "data['flag'] = label_encoder.fit_transform(data['flag'])\n",
    "data['class'] = label_encoder.fit_transform(data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527efe9",
   "metadata": {},
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d02bd",
   "metadata": {},
   "source": [
    "$isnull()$ is used to identify null/ missing values in the data\n",
    "$isnull().sum()$ will show us the total number of missing records in each column. For example, \"src_bytes\" and \"dst_bytes\" each have 6 values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1f5cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      6\n",
       "dst_bytes                      6\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "num_root                       0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          9\n",
       "srv_count                      9\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454867c",
   "metadata": {},
   "source": [
    "We are filling the missing values with the mean of all values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4074215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ac628",
   "metadata": {},
   "source": [
    "Now our dataset has only numerical values. This is easier to analyze using the machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ab8e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>12983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       45     1        0.0        0.0     0   \n",
       "1         0              1       45     1        0.0        0.0     0   \n",
       "2         2              1       19     9    12983.0        0.0     0   \n",
       "3         0              0       13     9       20.0        0.0     0   \n",
       "4         1              1       55     2        0.0       15.0     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  10   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  86   \n",
       "3               0       0    0  ...                  57   \n",
       "4               0       0    0  ...                  86   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.04                    0.06   \n",
       "1                    0.00                    0.06   \n",
       "2                    0.61                    0.04   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.31                    0.17   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.61                         0.02   \n",
       "3                         1.00                         0.28   \n",
       "4                         0.03                         0.02   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                  1.00   \n",
       "1                   0.0                       0.0                  1.00   \n",
       "2                   0.0                       0.0                  0.00   \n",
       "3                   0.0                       0.0                  0.00   \n",
       "4                   0.0                       0.0                  0.83   \n",
       "\n",
       "   dst_host_srv_rerror_rate  class  \n",
       "0                      1.00      0  \n",
       "1                      1.00      0  \n",
       "2                      0.00      1  \n",
       "3                      0.00      0  \n",
       "4                      0.71      0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee930c3a",
   "metadata": {},
   "source": [
    "Now we will split the independent variables or features from the target variables or labels. In other words, we will keep the features in $X$ variable the labels in $y$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f1251e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['class'])\n",
    "y = data['class'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d86f64",
   "metadata": {},
   "source": [
    "We will utilize stratified k-fold to maintain a uniform class distribution as the original dataset. This ensures that each fold is representative of the overall dataset, providing a more reliable estimate of the model's performance, particularly for classification tasks. Stratified k-fold is particularly useful when there is class imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3590806d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17224/1794496674.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5dc8c",
   "metadata": {},
   "source": [
    "The numerical values of the features are still unscaled and widely varied. Therefore, we need to scale the values. Scaling ensures that all features contribute equally to the model fitting process by bringing them to a similar scale. Without scaling, features with larger magnitudes may dominate those with smaller magnitudes, leading to biased model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf002c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741a560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14617ce4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a1327da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05b1cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ee9ff8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    prediction_lr = lr.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_lr)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_lr)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "23392582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9350188511865158, 0.9370148591705478, 0.936127744510978, 0.936127744510978, 0.9347826086956522]\n",
      "Mean Accuracy 0.9358143616149344\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d86af8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier: 0.9358\n",
      "Total testing data : 22544\n",
      "True Positive:  12235\n",
      "True Negative:  8862\n",
      "False Positive:  598\n",
      "Flase Negative:  849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9351    0.9534    0.9442     12833\n",
      "           1     0.9368    0.9126    0.9245      9711\n",
      "\n",
      "    accuracy                         0.9358     22544\n",
      "   macro avg     0.9359    0.9330    0.9343     22544\n",
      "weighted avg     0.9358    0.9358    0.9357     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "A = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', A[0][0] + A[0][1] + A[1][0] + A[1][1])\n",
    "print('True Positive: ', A[0][0])\n",
    "print('True Negative: ', A[1][1])\n",
    "print('False Positive: ', A[0][1])\n",
    "print('Flase Negative: ', A[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf340d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6cd9cd",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f1ef203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ab8894fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "16d55f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    prediction_rf = rf.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_rf)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_rf)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "033fd8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9880239520958084, 0.9878021734309159, 0.983810157462852, 0.9869150587713462, 0.9849157054125999]\n",
      "Mean Accuracy 0.9862934094347044\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5af4af50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier: 0.9863\n",
      "Total testing data : 22544\n",
      "True Positive:  12682\n",
      "True Negative:  9553\n",
      "False Positive:  151\n",
      "Flase Negative:  158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9877    0.9882    0.9880     12833\n",
      "           1     0.9844    0.9837    0.9841      9711\n",
      "\n",
      "    accuracy                         0.9863     22544\n",
      "   macro avg     0.9861    0.9860    0.9860     22544\n",
      "weighted avg     0.9863    0.9863    0.9863     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Random Forest classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "B = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', B[0][0] + B[0][1] + B[1][0] + B[1][1])\n",
    "print('True Positive: ', B[0][0])\n",
    "print('True Negative: ', B[1][1])\n",
    "print('False Positive: ', B[0][1])\n",
    "print('Flase Negative: ', B[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b089a2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9cc27945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "53853d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier() \n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "841b99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:48] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:49] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:50] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:04:51] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    prediction_xgb = xgb.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_xgb)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_xgb)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bf0a0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9897981814149479, 0.9889110667553781, 0.9866932801064537, 0.9878021734309159, 0.9889086069210293]\n",
      "Mean Accuracy 0.988422661725745\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d90c1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier: 0.9884\n",
      "Total testing data : 22544\n",
      "True Positive:  12701\n",
      "True Negative:  9582\n",
      "False Positive:  132\n",
      "Flase Negative:  129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9899    0.9897    0.9898     12833\n",
      "           1     0.9864    0.9867    0.9866      9711\n",
      "\n",
      "    accuracy                         0.9884     22544\n",
      "   macro avg     0.9882    0.9882    0.9882     22544\n",
      "weighted avg     0.9884    0.9884    0.9884     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Random Forest classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "B = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', B[0][0] + B[0][1] + B[1][0] + B[1][1])\n",
    "print('True Positive: ', B[0][0])\n",
    "print('True Negative: ', B[1][1])\n",
    "print('False Positive: ', B[0][1])\n",
    "print('Flase Negative: ', B[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e566adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "As we can see, XGBoost is already performing very well, returning F1 score of 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc3ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
