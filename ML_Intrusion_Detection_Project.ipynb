{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2efa7a3",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection based on Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aa14e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15011a7",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "53e95f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"network_intrusion_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c2c87",
   "metadata": {},
   "source": [
    "$head()$ will display the top 5 observations of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e83362fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>267.0</td>\n",
       "      <td>14515.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private  REJ        0.0        0.0     0   \n",
       "1         2           tcp  ftp_data   SF    12983.0        0.0     0   \n",
       "2         0          icmp     eco_i   SF       20.0        0.0     0   \n",
       "3         0           tcp      http   SF      267.0    14515.0     0   \n",
       "4         0           tcp      smtp   SF     1022.0      387.0     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                   1   \n",
       "1               0       0    0  ...                  86   \n",
       "2               0       0    0  ...                  57   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                  28   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.00                    0.06   \n",
       "1                    0.61                    0.04   \n",
       "2                    1.00                    0.00   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.11                    0.72   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.61                         0.02   \n",
       "2                         1.00                         0.28   \n",
       "3                         0.01                         0.03   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                       0.0                  1.00   \n",
       "1                  0.00                       0.0                  0.00   \n",
       "2                  0.00                       0.0                  0.00   \n",
       "3                  0.01                       0.0                  0.00   \n",
       "4                  0.00                       0.0                  0.72   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      1.00  anomaly  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  anomaly  \n",
       "3                      0.00   normal  \n",
       "4                      0.04   normal  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561025e9",
   "metadata": {},
   "source": [
    "### Analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11664e",
   "metadata": {},
   "source": [
    "$info()$ helps to understand the data type and information about data, including the number of records in each column, data having null or not null, Data type, the memory usage of the dataset.\n",
    "\n",
    "We can find that the network intrusion dataset has 40 columns, among them, \"protocol_type\", \"service\", \"flag\", and \"class\" columns are object type or categorical features (Not numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "21be6d2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16128 entries, 0 to 16127\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     16128 non-null  int64  \n",
      " 1   protocol_type                16128 non-null  object \n",
      " 2   service                      16128 non-null  object \n",
      " 3   flag                         16128 non-null  object \n",
      " 4   src_bytes                    16122 non-null  float64\n",
      " 5   dst_bytes                    16122 non-null  float64\n",
      " 6   land                         16128 non-null  int64  \n",
      " 7   wrong_fragment               16128 non-null  int64  \n",
      " 8   urgent                       16128 non-null  int64  \n",
      " 9   hot                          16128 non-null  int64  \n",
      " 10  num_failed_logins            16128 non-null  int64  \n",
      " 11  logged_in                    16128 non-null  int64  \n",
      " 12  num_compromised              16128 non-null  int64  \n",
      " 13  root_shell                   16128 non-null  int64  \n",
      " 14  num_root                     16128 non-null  int64  \n",
      " 15  num_shells                   16128 non-null  int64  \n",
      " 16  num_access_files             16128 non-null  int64  \n",
      " 17  num_outbound_cmds            16128 non-null  int64  \n",
      " 18  is_host_login                16128 non-null  int64  \n",
      " 19  is_guest_login               16128 non-null  int64  \n",
      " 20  count                        16121 non-null  float64\n",
      " 21  srv_count                    16121 non-null  float64\n",
      " 22  serror_rate                  16128 non-null  float64\n",
      " 23  srv_serror_rate              16128 non-null  float64\n",
      " 24  rerror_rate                  16128 non-null  float64\n",
      " 25  srv_rerror_rate              16128 non-null  float64\n",
      " 26  same_srv_rate                16128 non-null  float64\n",
      " 27  diff_srv_rate                16128 non-null  float64\n",
      " 28  srv_diff_host_rate           16128 non-null  float64\n",
      " 29  dst_host_count               16128 non-null  int64  \n",
      " 30  dst_host_srv_count           16128 non-null  int64  \n",
      " 31  dst_host_same_srv_rate       16128 non-null  float64\n",
      " 32  dst_host_diff_srv_rate       16128 non-null  float64\n",
      " 33  dst_host_same_src_port_rate  16128 non-null  float64\n",
      " 34  dst_host_srv_diff_host_rate  16128 non-null  float64\n",
      " 35  dst_host_serror_rate         16128 non-null  float64\n",
      " 36  dst_host_srv_serror_rate     16128 non-null  float64\n",
      " 37  dst_host_rerror_rate         16128 non-null  float64\n",
      " 38  dst_host_srv_rerror_rate     16128 non-null  float64\n",
      " 39  class                        16128 non-null  object \n",
      "dtypes: float64(19), int64(17), object(4)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cf76c",
   "metadata": {},
   "source": [
    "Some machine learning algorithms can handle categorical features directly without requiring them to be converted to numerical values. For example, Decision Trees and Random Forests can handle categorical variables naturally by splitting on different categories.\n",
    "\n",
    "However, many other algorithms, such as logistic regression, support vector machines, and neural networks, require numerical input. In such cases, converting categorical features to numerical values becomes necessary. This process is called \"encoding\" categorical variables.\n",
    "\n",
    "Since we will work with all classification models, we will use LabelEncoder() to convert the categorical features to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e07a963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['protocol_type'] = label_encoder.fit_transform(data['protocol_type'])\n",
    "data['service'] = label_encoder.fit_transform(data['service'])\n",
    "data['flag'] = label_encoder.fit_transform(data['flag'])\n",
    "data['class'] = label_encoder.fit_transform(data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "324c9963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>12983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>267.0</td>\n",
       "      <td>14515.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16123</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16124</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16125</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>794.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>317.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16128 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0             0              1       45     1        0.0        0.0     0   \n",
       "1             2              1       19     9    12983.0        0.0     0   \n",
       "2             0              0       13     9       20.0        0.0     0   \n",
       "3             0              1       22     9      267.0    14515.0     0   \n",
       "4             0              1       49     9     1022.0      387.0     0   \n",
       "...         ...            ...      ...   ...        ...        ...   ...   \n",
       "16123         0              1       25     1        0.0        0.0     0   \n",
       "16124         0              0       14     9     1032.0        0.0     0   \n",
       "16125         0              1       49     9      794.0      333.0     0   \n",
       "16126         0              1       22     9      317.0      938.0     0   \n",
       "16127         0              2       11     9       42.0       42.0     0   \n",
       "\n",
       "       wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0                   0       0    0  ...                   1   \n",
       "1                   0       0    0  ...                  86   \n",
       "2                   0       0    0  ...                  57   \n",
       "3                   0       0    0  ...                 255   \n",
       "4                   0       0    0  ...                  28   \n",
       "...               ...     ...  ...  ...                 ...   \n",
       "16123               0       0    0  ...                  18   \n",
       "16124               0       0    0  ...                 255   \n",
       "16125               0       0    0  ...                 141   \n",
       "16126               0       0    0  ...                 255   \n",
       "16127               0       0    0  ...                 252   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                        0.00                    0.06   \n",
       "1                        0.61                    0.04   \n",
       "2                        1.00                    0.00   \n",
       "3                        1.00                    0.00   \n",
       "4                        0.11                    0.72   \n",
       "...                       ...                     ...   \n",
       "16123                    0.07                    0.05   \n",
       "16124                    1.00                    0.00   \n",
       "16125                    0.72                    0.06   \n",
       "16126                    1.00                    0.00   \n",
       "16127                    0.99                    0.01   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                             0.00                         0.00   \n",
       "1                             0.61                         0.02   \n",
       "2                             1.00                         0.28   \n",
       "3                             0.01                         0.03   \n",
       "4                             0.00                         0.00   \n",
       "...                            ...                          ...   \n",
       "16123                         0.00                         0.00   \n",
       "16124                         1.00                         0.00   \n",
       "16125                         0.01                         0.01   \n",
       "16126                         0.01                         0.01   \n",
       "16127                         0.00                         0.00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                      0.00                       0.0                  1.00   \n",
       "1                      0.00                       0.0                  0.00   \n",
       "2                      0.00                       0.0                  0.00   \n",
       "3                      0.01                       0.0                  0.00   \n",
       "4                      0.00                       0.0                  0.72   \n",
       "...                     ...                       ...                   ...   \n",
       "16123                  0.00                       0.0                  1.00   \n",
       "16124                  0.00                       0.0                  0.00   \n",
       "16125                  0.01                       0.0                  0.00   \n",
       "16126                  0.01                       0.0                  0.00   \n",
       "16127                  0.00                       0.0                  0.00   \n",
       "\n",
       "       dst_host_srv_rerror_rate  class  \n",
       "0                          1.00      0  \n",
       "1                          0.00      1  \n",
       "2                          0.00      0  \n",
       "3                          0.00      1  \n",
       "4                          0.04      1  \n",
       "...                         ...    ...  \n",
       "16123                      1.00      0  \n",
       "16124                      0.00      0  \n",
       "16125                      0.00      1  \n",
       "16126                      0.00      1  \n",
       "16127                      0.00      1  \n",
       "\n",
       "[16128 rows x 40 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f2d33",
   "metadata": {},
   "source": [
    "### Checking class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d890c8e",
   "metadata": {},
   "source": [
    "We need to check for class imbalance in the dataset, which means, we need to check if the ratio of normal data (now converted to 0) and anomalous data (now converted to 1) is equal or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8fa71067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data labeled as 'anomaly': 9711\n",
      "Number of data labeled as 'normal': 6417\n"
     ]
    }
   ],
   "source": [
    "label_counts = data['class'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of data labeled as 'anomaly':\", label_counts[1])\n",
    "print(\"Number of data labeled as 'normal':\", label_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50f670",
   "metadata": {},
   "source": [
    "As we can see, the dataset has more normal data than anomalous data, resulting in a class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ff495",
   "metadata": {},
   "source": [
    "### Checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b5c58",
   "metadata": {},
   "source": [
    "$isnull()$ is used to identify null/ missing values in the data\n",
    "$isnull().sum()$ will show us the total number of missing records in each column. For example, \"src_bytes\" and \"dst_bytes\" each have 6 values missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6645c956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      6\n",
       "dst_bytes                      6\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "num_root                       0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          7\n",
       "srv_count                      7\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce433fb",
   "metadata": {},
   "source": [
    "We are filling the missing values with the mean of all values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4074215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517a7d7",
   "metadata": {},
   "source": [
    "Now our dataset has only numerical values. This is easier to analyze using the machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4ab8e139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>12983.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>267.0</td>\n",
       "      <td>14515.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       45     1        0.0        0.0     0   \n",
       "1         2              1       19     9    12983.0        0.0     0   \n",
       "2         0              0       13     9       20.0        0.0     0   \n",
       "3         0              1       22     9      267.0    14515.0     0   \n",
       "4         0              1       49     9     1022.0      387.0     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                   1   \n",
       "1               0       0    0  ...                  86   \n",
       "2               0       0    0  ...                  57   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                  28   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.00                    0.06   \n",
       "1                    0.61                    0.04   \n",
       "2                    1.00                    0.00   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.11                    0.72   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.61                         0.02   \n",
       "2                         1.00                         0.28   \n",
       "3                         0.01                         0.03   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                       0.0                  1.00   \n",
       "1                  0.00                       0.0                  0.00   \n",
       "2                  0.00                       0.0                  0.00   \n",
       "3                  0.01                       0.0                  0.00   \n",
       "4                  0.00                       0.0                  0.72   \n",
       "\n",
       "   dst_host_srv_rerror_rate  class  \n",
       "0                      1.00      0  \n",
       "1                      0.00      1  \n",
       "2                      0.00      0  \n",
       "3                      0.00      1  \n",
       "4                      0.04      1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d7ad7",
   "metadata": {},
   "source": [
    "Now we will split the independent variables or features from the target variables or labels. In other words, we will keep the features in $X$ variable the labels in $y$ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f1251e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['class'])\n",
    "y = data['class'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f4510",
   "metadata": {},
   "source": [
    "We will utilize stratified k-fold to maintain a uniform class distribution as the original dataset. This ensures that each fold is representative of the overall dataset, providing a more reliable estimate of the model's performance, particularly for classification tasks. Stratified k-fold is particularly useful when there is class imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3590806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ab400",
   "metadata": {},
   "source": [
    "The numerical values of the features are still unscaled and widely varied. Therefore, we need to scale the values. Scaling ensures that all features contribute equally to the model fitting process by bringing them to a similar scale. Without scaling, features with larger magnitudes may dominate those with smaller magnitudes, leading to biased model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "60268bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 5.00000000e-01, 7.14285714e-01, ...,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [3.67302713e-05, 5.00000000e-01, 3.01587302e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.06349206e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 5.00000000e-01, 7.77777778e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 5.00000000e-01, 3.49206349e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00, 1.74603175e-01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741a560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14617ce4",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a1327da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "05b1cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ee9ff8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    prediction_lr = lr.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_lr)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_lr)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "23392582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9228146311221327, 0.9175449473031618, 0.9187848729076256, 0.9147286821705426, 0.9196899224806202]\n",
      "Mean Accuracy 0.9187126111968166\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d86af8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier: 0.9187\n",
      "Total testing data : 16128\n",
      "True Positive:  5502\n",
      "True Negative:  9315\n",
      "False Positive:  915\n",
      "Flase Negative:  396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9329    0.8574    0.8935      6417\n",
      "           1     0.9106    0.9592    0.9343      9711\n",
      "\n",
      "    accuracy                         0.9187     16128\n",
      "   macro avg     0.9217    0.9083    0.9139     16128\n",
      "weighted avg     0.9194    0.9187    0.9181     16128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "A = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', A[0][0] + A[0][1] + A[1][0] + A[1][1])\n",
    "print('True Positive: ', A[0][0])\n",
    "print('True Negative: ', A[1][1])\n",
    "print('False Positive: ', A[0][1])\n",
    "print('Flase Negative: ', A[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf340d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db6cd9cd",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f1ef203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab8894fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "16d55f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    prediction_rf = rf.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_rf)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_rf)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "033fd8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9888406695598264, 0.9885306881587105, 0.9851208927464352, 0.9872868217054264, 0.9872868217054264]\n",
      "Mean Accuracy 0.9874131787751649\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5af4af50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier: 0.9874\n",
      "Total testing data : 16128\n",
      "True Positive:  6300\n",
      "True Negative:  9625\n",
      "False Positive:  117\n",
      "Flase Negative:  86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9865    0.9818    0.9841      6417\n",
      "           1     0.9880    0.9911    0.9896      9711\n",
      "\n",
      "    accuracy                         0.9874     16128\n",
      "   macro avg     0.9873    0.9865    0.9869     16128\n",
      "weighted avg     0.9874    0.9874    0.9874     16128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Random Forest classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "B = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', B[0][0] + B[0][1] + B[1][0] + B[1][1])\n",
    "print('True Positive: ', B[0][0])\n",
    "print('True Negative: ', B[1][1])\n",
    "print('False Positive: ', B[0][1])\n",
    "print('Flase Negative: ', B[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b089a2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9cc27945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "53853d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier() \n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "841b99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:13] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:14] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:16] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:17] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehra\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:19] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    \n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "    prediction_xgb = xgb.predict(X_test)\n",
    "    \n",
    "    true_labels.extend(y_test)\n",
    "    pred_labels.extend(prediction_xgb)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, prediction_xgb)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bf0a0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold Accuracies [0.9913205207687539, 0.9903905765654061, 0.9882207067575945, 0.9882170542635659, 0.9875968992248062]\n",
      "Mean Accuracy 0.9891491515160254\n"
     ]
    }
   ],
   "source": [
    "print('5-fold Accuracies', accuracies)\n",
    "print('Mean Accuracy', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d90c1a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier: 0.9891\n",
      "Total testing data : 16128\n",
      "True Positive:  6312\n",
      "True Negative:  9641\n",
      "False Positive:  105\n",
      "Flase Negative:  70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9890    0.9836    0.9863      6417\n",
      "           1     0.9892    0.9928    0.9910      9711\n",
      "\n",
      "    accuracy                         0.9891     16128\n",
      "   macro avg     0.9891    0.9882    0.9887     16128\n",
      "weighted avg     0.9891    0.9891    0.9891     16128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Random Forest classifier: {:.4f}'.format(accuracy_score(true_labels, pred_labels)))\n",
    "B = confusion_matrix(true_labels, pred_labels)\n",
    "print('Total testing data :', B[0][0] + B[0][1] + B[1][0] + B[1][1])\n",
    "print('True Positive: ', B[0][0])\n",
    "print('True Negative: ', B[1][1])\n",
    "print('False Positive: ', B[0][1])\n",
    "print('Flase Negative: ', B[1][0])\n",
    "print(classification_report(true_labels, pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14788116",
   "metadata": {},
   "source": [
    "As we can see, XGBoost is already performing very well, returning F1 score of 98.91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc3ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9783e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae8b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637efd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
